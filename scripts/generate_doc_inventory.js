#!/usr/bin/env node
'use strict';
import fs from 'fs';
import path from 'path';
import crypto from 'crypto';

const repoRoot = process.cwd();
const OUTPUT_DIR = path.join(repoRoot, 'docs');
const JSON_OUT = path.join(OUTPUT_DIR, 'doc_inventory.json');
const MD_OUT = path.join(OUTPUT_DIR, 'doc_inventory.md');

function toForwardSlash(p) {
  return p.split(path.sep).join('/');
}

function relPath(abs) {
  return toForwardSlash(path.relative(repoRoot, abs));
}

function md5OfBuffer(buf) {
  return crypto.createHash('md5').update(buf).digest('hex');
}

function scanDir(start) {
  const results = [];
  const stack = [start];
  while (stack.length) {
    const dir = stack.pop();
    let entries;
    try {
      entries = fs.readdirSync(dir, { withFileTypes: true });
    } catch (err) {
      continue; // skip unreadable dirs
    }
    for (const e of entries) {
      const full = path.join(dir, e.name);
      if (e.isDirectory()) {
        stack.push(full);
        continue;
      }
      if (!e.isFile()) continue;
      const ext = path.extname(e.name).toLowerCase();
      if (ext === '.md' || ext === '.txt') results.push(full);
    }
  }
  return results;
}

function extractHeaderTimestamp(lines) {
  const headerLines = lines.slice(0, 20);
  const rx = /^(?:CreatedAt|created_at|Timestamp|Date|LastUpdated)\s*:\s*(.+)$/i;
  for (const l of headerLines) {
    const m = l.match(rx);
    if (m) return m[1].trim();
  }
  return null;
}

function classify(rel, filename, content) {
  const lowerRel = rel.toLowerCase();
  const lowerFile = filename.toLowerCase();
  const goldTokens = [
    'pinch_feature',
    'pinch_mvp',
    'pinch',
    'hope_notebook',
    'gameboard',
    'videogoldens',
    'tectangle_summary',
    'consolidated_pinch_report',
    'agent.md'
  ];
  for (const t of goldTokens) {
    if (lowerRel.includes(t) || lowerFile.includes(t)) return 'Gold';
  }
  if (lowerRel.includes('/docs/') && (lowerFile.includes('summary') || lowerFile.includes('decision'))) {
    return 'Gold';
  }
  if (lowerRel.includes('/archive/') || lowerRel.includes('/archive-stale/')) return 'AI-slop';
  if (/auto-generated|generated by|assistant/i.test(content)) return 'AI-slop';
  return 'Reference';
}

(async function main() {
  try {
    const files = scanDir(repoRoot);
    const excluded = new Set(['docs/doc_inventory.json','docs/doc_inventory.md'].map(p => toForwardSlash(p)));
    const entries = [];
    const counts = { Gold: 0, Reference: 0, 'AI-slop': 0 };
    for (const f of files) {
      const rel = relPath(f);
      if (excluded.has(rel)) continue;
      let buf;
      try {
        buf = fs.readFileSync(f);
      } catch (err) {
        // skip unreadable file
        continue;
      }
      const content = buf.toString('utf8');
      let stats;
      try {
        stats = fs.statSync(f);
      } catch (err) {
        stats = { size: Buffer.byteLength(content, 'utf8') };
      }
      const lines = content.split(/\r?\n/);
      const header_timestamp = extractHeaderTimestamp(lines);
      const excerpt = lines.slice(0, 40).join('\n');
      const word_count = content.split(/\s+/).filter(Boolean).length;
      const md5 = md5OfBuffer(buf);
      const filename = path.basename(f);
      const classification = classify(rel, filename, content);
      counts[classification] = (counts[classification]||0)+1;
      entries.push({
        path: rel,
        size: stats.size,
        word_count,
        header_timestamp,
        excerpt,
        md5,
        classification
      });
    }

    entries.sort((a,b)=>a.path.localeCompare(b.path));

    const generatedAt = new Date().toISOString();
    const summary = {
      generatedAt,
      repo: path.basename(repoRoot),
      total_files: entries.length,
      counts,
      entries
    };

    await fs.promises.mkdir(OUTPUT_DIR, { recursive: true });
    await fs.promises.writeFile(JSON_OUT, JSON.stringify(summary, null, 2), 'utf8');

    // Build markdown wrapper
    const topHeader = `Generated at ${generatedAt} â€” repo ${summary.repo}. ${summary.total_files} files found (Gold: ${counts.Gold}, Reference: ${counts.Reference}, AI-slop: ${counts['AI-slop']}).`;
    const jsonBlock = JSON.stringify(summary, null, 2);
    const topBySize = entries.slice().sort((a,b)=>b.size - a.size).slice(0,10);
    const topByWords = entries.slice().sort((a,b)=>b.word_count - a.word_count).slice(0,10);
    let md = `# Document Inventory

${topHeader}

\`\`\`json
${jsonBlock}
\`\`\`

## Top 10 largest files

`;
    for (const e of topBySize) md += `- ${e.path} (${e.size} bytes)\n`;
    md += `

## Top 10 by word_count

`;
    for (const e of topByWords) md += `- ${e.path} (${e.word_count} words)\n`;

    await fs.promises.writeFile(MD_OUT, md, 'utf8');

    console.log(`Scanned ${entries.length} files. Counts: Gold=${counts.Gold} Reference=${counts.Reference} AI-slop=${counts['AI-slop']}`);
    console.log(`Wrote ${toForwardSlash(path.relative(repoRoot, JSON_OUT))} and ${toForwardSlash(path.relative(repoRoot, MD_OUT))}`);
    process.exit(0);
  } catch (err) {
    console.error(err && err.stack ? err.stack : String(err));
    process.exit(1);
  }
})();